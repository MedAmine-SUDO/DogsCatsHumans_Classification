{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOX3JKA2ur0pG884DxQSyhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedAmine-SUDO/DogsCatsHumans_Classification/blob/test/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUNV21Yrw3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2                \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# extract pre-trained face detector\n",
        "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
        "\n",
        "def face_detector(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    return faces\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbCiPM4gtNhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example(image):\n",
        "\t# load the image\n",
        "\timg = load_image(image)\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\treturn int(result[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lWfKRPntPYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_PATH = \"\"\n",
        "\n",
        "if(len(face_detector(IMAGE_PATH)) > 1 ):\n",
        "    print(\"Hey Humans ...\")\n",
        "elif(len(face_detector(IMAGE_PATH)) = 1):\n",
        "    print(\"Hey Human ..\")\n",
        "    for (x,y,w,h) in faces:\n",
        "        # add bounding box to color image\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    \n",
        "    # convert BGR image to RGB for plotting\n",
        "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # display the image, along with bounding box\n",
        "    plt.imshow(cv_rgb)\n",
        "    plt.show()\n",
        "else:\n",
        "    if(run_example(IMAGE_PATH) == 1):\n",
        "        print(\"Hey Dogy ..\")\n",
        "    else:\n",
        "        print(\"Hey Kitty ..\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}