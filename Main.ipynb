{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KIbtxUHVvBEFJTYmhc36LtaHMKSTm-xb",
      "authorship_tag": "ABX9TyN3hUCmtkIr+80B4Ye3hit3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedAmine-SUDO/DogsCatsHumans_Classification/blob/master/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sovmPvr6vdS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure that your current directory is your project \"DogCatHuman\"; using cd command change the current directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc7XxghPbBg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUNV21Yrw3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2                \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# extract pre-trained face detector\n",
        "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
        "\n",
        "def face_detector(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    return faces\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbCiPM4gtNhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7650c999-622e-4471-91ed-d198b10af1b2"
      },
      "source": [
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example(image):\n",
        "\t# load the image\n",
        "\timg = load_image(image)\n",
        "\t# load model\n",
        "\tmodel = load_model('./final_model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\treturn int(result[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lWfKRPntPYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbaf0986-ed7f-4251-8412-a5812f462031"
      },
      "source": [
        "#Change IMAGE_PATH with the name of image you want to test\n",
        "#Make sure images are in the same directory of this notebook (main.ipynb)\n",
        "IMAGE_PATH = \"./peoples.jpg\"\n",
        "\n",
        "if(len(face_detector(IMAGE_PATH)) > 1 ):\n",
        "    print(\"Hey Humans ...\")\n",
        "elif(len(face_detector(IMAGE_PATH)) == 1):\n",
        "    print(\"Hey Human ..\")\n",
        "    img = cv2.imread(IMAGE_PATH)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    for (x,y,w,h) in faces:\n",
        "        # add bounding box to color image\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    \n",
        "    # convert BGR image to RGB for plotting\n",
        "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # display the image, along with bounding box\n",
        "    plt.imshow(cv_rgb)\n",
        "    plt.show()\n",
        "else:\n",
        "    if(run_example(IMAGE_PATH) == 1):\n",
        "        print(\"Hey Dogy ..\")\n",
        "    else:\n",
        "        print(\"Hey Kitty ..\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hey Humans ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQI-X8XFwP4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}